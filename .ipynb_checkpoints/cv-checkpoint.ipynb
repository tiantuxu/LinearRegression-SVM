{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(scores):\n",
    "    predictions = np.zeros(len(scores))\n",
    "    for i in range(len(predictions)):\n",
    "        if scores[i] >= 0:\n",
    "            predictions[i] +=  1.0 / (1.0 + np.exp(-scores[i]))\n",
    "        else:\n",
    "            predictions[i] += np.exp(scores[i]) / (1.0 + np.exp(scores[i]))\n",
    "    return predictions\n",
    "\n",
    "def lr(trainingSet, testSet):\n",
    "    #print len(trainingSet.columns)\n",
    "    regularization = 0.01\n",
    "    step_size = 0.01\n",
    "    \n",
    "    max_iterations = 500\n",
    "    tol = 1e-6\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    \n",
    "    #print train_labels, trainingSet\n",
    "    w = np.zeros(len(trainingSet.columns) + 1)\n",
    "    \n",
    "    # Add intercept\n",
    "    X = np.array(trainingSet)\n",
    "    Y = np.array(train_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    #X = np.concatenate((X, intercept.T), axis=1)\n",
    "    X = np.hstack((X, intercept))\n",
    "    diff = 100.0\n",
    "    \n",
    "    while(count < max_iterations and diff > tol):\n",
    "        count += 1\n",
    "        norm_old = np.linalg.norm(w)\n",
    "        \n",
    "        scores = np.dot(X, w)\n",
    "        predictions = sigmoid(scores)\n",
    "\n",
    "        gradient = np.dot(X.T, (predictions - Y))\n",
    "\n",
    "        for j in range(len(w)):\n",
    "            gradient[j] += regularization * w[j]\n",
    "            \n",
    "        #gradient /= len(train_labels)\n",
    "        w -= step_size * gradient\n",
    "        norm_new = np.linalg.norm(w)\n",
    "        \n",
    "        diff = abs(norm_new - norm_old)\n",
    "        #print w\n",
    "        #print count, diff\n",
    "    \n",
    "    return w\n",
    "\n",
    "def svm(trainingSet, testSet):\n",
    "    #print len(trainingSet.columns)\n",
    "    regularization = 0.01\n",
    "    step_size = 0.50\n",
    "    \n",
    "    max_iterations = 500\n",
    "    tol = 1e-6\n",
    "    #print len(trainingSet[trainingSet['decision'] == 1])\n",
    "    count = 0\n",
    "    train_labels = trainingSet['decision']    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "\n",
    "    w = np.zeros(len(trainingSet.columns) + 1)\n",
    "    \n",
    "    # Add intercept\n",
    "    X = np.array(trainingSet)\n",
    "    Y = np.array(train_labels)\n",
    "    #print train_labels\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == 0:\n",
    "            Y[i] = -1.0\n",
    "        else:\n",
    "            Y[i] = 1.0\n",
    "    #print Y.tolist()\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((intercept, X))\n",
    "    diff = 100.0\n",
    "    while(count < max_iterations and diff > tol):\n",
    "        count += 1\n",
    "        norm_old = np.linalg.norm(w)\n",
    "        \n",
    "        predictions = np.dot(X, w)\n",
    "    \n",
    "        error = 0\n",
    "        gradient = np.zeros(len(w))\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i] * Y[i] < 1.0:\n",
    "                error += 1\n",
    "                #gradient -= 1.0 * Y[i] * X[i]\n",
    "                gradient -= np.multiply(X[i], Y[i])\n",
    "            \n",
    "        gradient /= 1.0 * len(train_labels)\n",
    "        #print gradient.shape, X[0].shape\n",
    "        \n",
    "        for j in range(1, len(gradient)):\n",
    "            gradient[j] += 1.0 * regularization * w[j]\n",
    "\n",
    "        w -= 1.0 * step_size * gradient\n",
    "        norm_new = np.linalg.norm(w)\n",
    "        diff = abs(norm_new - norm_old)\n",
    "        #print count, diff, error\n",
    "    #print w\n",
    "    return w\n",
    "\n",
    "def nbc(trainingSet, testSet):\n",
    "    attr_list = list(trainingSet[trainingSet.columns.difference(['decision'])])\n",
    "    dict_table ={}\n",
    "    \n",
    "    # Labels\n",
    "    dict_labels = {}\n",
    "    dict_labels['no'] = len(trainingSet[trainingSet['decision'] == 0])\n",
    "    dict_labels['yes'] = len(trainingSet[trainingSet['decision'] == 1])\n",
    "    dict_table['decision'] = dict_labels\n",
    "    \n",
    "    # Attributes in discrete_columns\n",
    "    for attr in attr_list:\n",
    "        dict_attr = {}\n",
    "        attr_bin = max(int(trainingSet[attr].max()), int(testSet[attr].max()))\n",
    "        \n",
    "        dict_attr['no'] = [0 for i in range(attr_bin + 1)]\n",
    "        dict_attr['yes'] = [0 for i in range(attr_bin + 1)]\n",
    "        \n",
    "        for i in range(attr_bin+1):\n",
    "            dict_attr['no'][i] += len(trainingSet[(trainingSet[attr] == i) & (trainingSet['decision'] == 0)])\n",
    "            dict_attr['yes'][i] += len(trainingSet[(trainingSet[attr] == i) & (trainingSet['decision'] == 1)])\n",
    "\n",
    "        dict_table[attr] = dict_attr\n",
    "        \n",
    "    return dict_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_lr(w, trainingSet, testSet):\n",
    "    total_train = len(trainingSet)\n",
    "    count_train = 0\n",
    "    total_test = len(testSet)\n",
    "    count_test = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = np.array(testSet['decision'])\n",
    "    #print test_labels\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    # Test accuracy\n",
    "    X = np.array(testSet)\n",
    "    Y = np.array(test_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((X, intercept))\n",
    "\n",
    "    scores = np.dot(X, w)\n",
    "    predictions = sigmoid(scores)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] > 0.5:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "\n",
    "    for i in range(len(predictions)):    \n",
    "        if predictions[i] == int(Y[i]):\n",
    "            count_test += 1\n",
    "            \n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    print 'Test Accuracy LR:', '%.2f' % test_accuracy\n",
    "    return test_accuracy\n",
    "    \n",
    "def get_accuracy_svm(w, trainingSet, testSet):\n",
    "    total_train = len(trainingSet)\n",
    "    count_train = 0\n",
    "    total_test = len(testSet)\n",
    "    count_test = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = testSet['decision']\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    # Test accuracy\n",
    "    X = np.array(testSet)\n",
    "    Y = np.array(test_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((intercept, X))\n",
    "\n",
    "    predictions = np.dot(X, w)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] > 0.0:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "\n",
    "    for i in range(len(predictions)):    \n",
    "        if predictions[i] == int(Y[i]):\n",
    "            count_test += 1\n",
    "            \n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    print 'Test Accuracy SVM:', '%.2f' % test_accuracy\n",
    "    return test_accuracy\n",
    "\n",
    "def get_accuracy_nbc(dict_table, trainingSet, testSet):\n",
    "    # Accuracy on training data\n",
    "    (row, col) = trainingSet.shape\n",
    "    attr_list = list(trainingSet[trainingSet.columns.difference(['decision'])])\n",
    "    \n",
    "    neg_num = len(trainingSet[trainingSet['decision'] == 0])\n",
    "    pos_num = len(trainingSet[trainingSet['decision'] == 1])\n",
    "    \n",
    "    # Accuracy on test data\n",
    "    (row_test, col_test) = testSet.shape\n",
    "    \n",
    "    row_index_test = testSet.index.tolist()\n",
    "\n",
    "    correct = 0\n",
    "    for i in row_index_test:\n",
    "        pd_pos = 1.0 * dict_table['decision']['yes']/row\n",
    "        pd_neg = 1.0 * dict_table['decision']['no']/row\n",
    "        #print pd_pos, pd_neg\n",
    "        for attr in attr_list:\n",
    "            pd_pos *= 1.0 * dict_table[attr]['yes'][int(testSet[attr][i])]/pos_num\n",
    "            pd_neg *= 1.0 * dict_table[attr]['no'][int(testSet[attr][i])]/neg_num\n",
    "        \n",
    "        res = np.argmax([1.0 * pd_neg, 1.0 * pd_pos])\n",
    "        if res == testSet['decision'][i]:\n",
    "            correct += 1\n",
    "    test_accuracy = 1.0 * correct/row_test\n",
    "    print 'Test Accuracy NBC:', '%.2f' % test_accuracy\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binned_data(bin_value):\n",
    "    df = pd.read_csv('dating-full.csv').head(6500)\n",
    "    #df = pd.head(6500)\n",
    "    (row, col) = df.shape\n",
    "\n",
    "    # strip\n",
    "    df['race'] = df['race'].str.replace(\"'\",\"\")\n",
    "    df['race_o'] = df['race_o'].str.replace(\"'\",\"\")\n",
    "    df['field'] = df['field'].str.replace(\"'\",\"\")\n",
    "    \n",
    "    # lower case\n",
    "    df['field'] = df['field'].str.lower()\n",
    "    \n",
    "    # gender\n",
    "    df['gender'] = df['gender'].astype('category')\n",
    "    df['gender'] = df['gender'].cat.codes    \n",
    "    # race\n",
    "    df['race'] = df['race'].astype('category')\n",
    "    df['race'] = df['race'].cat.codes\n",
    "    #print d['race']    \n",
    "    # race_o\n",
    "    df['race_o'] = df['race_o'].astype('category')\n",
    "    df['race_o'] = df['race_o'].cat.codes    \n",
    "    # field\n",
    "    df['field'] = df['field'].astype('category')\n",
    "    df['field'] = df['field'].cat.codes\n",
    "    \n",
    "    # Normalize the score\n",
    "    preference_scores_of_participant  = \\\n",
    "    ['attractive_important', 'sincere_important', 'intelligence_important',\\\n",
    "     'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "\n",
    "    preference_scores_of_partner = \\\n",
    "    ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', \\\n",
    "     'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\n",
    "\n",
    "    for i in range(row):\n",
    "        participant_sum = 0\n",
    "        partner_sum = 0\n",
    "    \n",
    "        for pref in preference_scores_of_participant:\n",
    "            participant_sum += df[pref][i]\n",
    "            \n",
    "        for pref in preference_scores_of_partner:\n",
    "            partner_sum += df[pref][i]\n",
    "        \n",
    "        # update the preference scores of participant\n",
    "        for pref in preference_scores_of_participant:\n",
    "            df.loc[i, pref] = df[pref][i]/participant_sum\n",
    "            \n",
    "        # update the preference scores of partner\n",
    "        for pref in preference_scores_of_partner:\n",
    "            df.loc[i, pref] = df[pref][i]/partner_sum\n",
    "        \n",
    "    discrete_columns = ['gender', 'race', 'race_o', 'samerace', 'field', 'decision']\n",
    "    all_columns = df.columns.values.tolist()\n",
    "    continuous_valued_columns = [item for item in all_columns if item not in discrete_columns]\n",
    "\n",
    "    (row, col) = df.shape\n",
    "    age_range = [18.0, 58.0]\n",
    "    pref_score = [0.0, 1.0]\n",
    "    score = [0.0, 10.0]\n",
    "    corr_range = [-1.00, 1.00]\n",
    "    \n",
    "    bin_seg = [1.000 * i/bin_value for i in range(0, bin_value + 1)]\n",
    "    #print bin_seg\n",
    "\n",
    "    age = ['age', 'age_o']\n",
    "    corr = ['interests_correlate']\n",
    "    preference_scores_of_participant = \\\n",
    "    ['attractive_important', 'sincere_important', 'intelligence_important',\\\n",
    "     'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "    \n",
    "    preference_scores_of_partner = \\\n",
    "    ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', \\\n",
    "     'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\n",
    "    \n",
    "    continuous_valued_columns_bins = {}\n",
    "    \n",
    "    # Segment the bins\n",
    "    for field in continuous_valued_columns:\n",
    "        continuous_valued_columns_bins[field] = []\n",
    "        if field in age:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(age_range[0] + bin_seg[i] * (age_range[1] - age_range[0]))\n",
    "        elif field in corr:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(corr_range[0] + bin_seg[i] * (corr_range[1] - corr_range[0]))\n",
    "        elif field in preference_scores_of_participant or field in preference_scores_of_partner:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(pref_score[0] + bin_seg[i] * (pref_score[1] - pref_score[0]))\n",
    "        else:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(score[0] + bin_seg[i] * (score[1] - score[0]))\n",
    "    \n",
    "    # Dictionary of the numbers ine ach bin\n",
    "    continuous_valued_columns_seg = {}\n",
    "    # Initalize the dict\n",
    "    for field in continuous_valued_columns:\n",
    "        continuous_valued_columns_seg[field] = [0 for i in range(bin_value)]\n",
    "    \n",
    "    for i in range(row):\n",
    "        for field in continuous_valued_columns:\n",
    "            # Find the bin\n",
    "            for j in range(0, bin_value):\n",
    "                # Corner Case\n",
    "                if j == 0:\n",
    "                    if continuous_valued_columns_bins[field][j] <= float(df[field][i]) <= continuous_valued_columns_bins[field][j + 1]:\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "                elif j == bin_value - 1:\n",
    "                    if continuous_valued_columns_bins[field][j] < float(df[field][i]):\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "                else:\n",
    "                    if continuous_valued_columns_bins[field][j] < float(df[field][i]) <= continuous_valued_columns_bins[field][j + 1]:\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "        \n",
    "    df = df.astype('int64')\n",
    "    df_test = df.sample(frac=0.2, random_state=25)    \n",
    "    # Subtract \n",
    "    df_train = df[~df.index.isin(df_test.index)]\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataFilename = 'trainingSet.csv'\n",
    "testDataFilename = 'testSet.csv'\n",
    "trainingSet = pd.read_csv(trainingDataFilename)\n",
    "testSet = pd.read_csv(testDataFilename)\n",
    "\n",
    "trainingSet_nbc, testSet_nbc = get_binned_data(5)\n",
    "\n",
    "f = [0.025, 0.05, 0.075, 0.1, 0.15, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the training set\n",
    "trainingSet = trainingSet.sample(frac=1, random_state=18)\n",
    "trainingSet_nbc = trainingSet_nbc.sample(frac=1, random_state=18)\n",
    "\n",
    "df_kfold = []\n",
    "for i in range(10):\n",
    "    df_kfold.append(trainingSet[i*520:(i+1)*520])\n",
    "    \n",
    "df_kfold_nbc = []\n",
    "for i in range(10):\n",
    "    df_kfold_nbc.append(trainingSet_nbc[i*520:(i+1)*520])\n",
    "    \n",
    "nbc_res = {}\n",
    "lr_res = {}\n",
    "svm_res = {}\n",
    "\n",
    "for t_frac in f:\n",
    "    nbc_res[t_frac] = []\n",
    "    lr_res[t_frac] = []\n",
    "    svm_res[t_frac] = []\n",
    "#print nbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f = 0.025\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.72\n",
      "Test Accuracy SVM: 0.65\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.61\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.60\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.72\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.58\n",
      "Test Accuracy LR: 0.58\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.58\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.51\n",
      "Test Accuracy NBC: 0.60\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.50\n",
      "Test Accuracy NBC: 0.59\n",
      "Test Accuracy LR: 0.59\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.60\n",
      "f = 0.05\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.48\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.60\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.63\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.61\n",
      "f = 0.075\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.48\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.65\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.65\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "f = 0.1\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.71\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.70\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "f = 0.15\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.70\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.60\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.65\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.69\n",
      "f = 0.2\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.71\n",
      "Test Accuracy SVM: 0.61\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.74\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.72\n"
     ]
    }
   ],
   "source": [
    "for t_frac in f:\n",
    "    print 'f =' , t_frac\n",
    "    for i in range(10):\n",
    "        # Partition the tarin and cv\n",
    "        train_set_df = []\n",
    "        train_set_nbc_df = []\n",
    "        \n",
    "        for j in range(10):\n",
    "            if j != i:\n",
    "                train_set_df.append(df_kfold[j])\n",
    "                train_set_nbc_df.append(df_kfold_nbc[j])\n",
    "            else:\n",
    "                test_set = df_kfold[j]\n",
    "                test_set_nbc = df_kfold_nbc[j]\n",
    "        \n",
    "        train_set = pd.concat(train_set_df).sample(frac=t_frac, random_state=32)\n",
    "        train_set_nbc = pd.concat(train_set_nbc_df).sample(frac=t_frac, random_state=32)\n",
    "        #print train_set\n",
    "        \n",
    "        # Train and Test\n",
    "        w = lr(train_set, test_set)\n",
    "        lr_res[t_frac].append(get_accuracy_lr(w, train_set, test_set))\n",
    "\n",
    "        w = svm(train_set, test_set)\n",
    "        svm_res[t_frac].append(get_accuracy_svm(w, train_set, test_set))\n",
    "        \n",
    "        dict_nbc = nbc(train_set_nbc, test_set_nbc)\n",
    "        nbc_res[t_frac].append(get_accuracy_nbc(dict_nbc, train_set_nbc, test_set_nbc))\n",
    "\n",
    "#print lr_res\n",
    "#print svm_res\n",
    "#print nbc_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6540384615384616, 0.6476923076923077, 0.6609615384615385, 0.6819230769230769, 0.6509615384615385, 0.6573076923076921] [0.5567307692307691, 0.5521153846153847, 0.5590384615384615, 0.5655769230769232, 0.5767307692307692, 0.5690384615384615]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = [0.025, 0.05, 0.075, 0.1, 0.15, 0.2]\n",
    "# Get avg accuracy\n",
    "nbc_avg = []\n",
    "lr_avg = []\n",
    "svm_avg = []\n",
    "\n",
    "# Get std error\n",
    "nbc_stdrr = []\n",
    "lr_stdrr = []\n",
    "svm_stdrr = []\n",
    "\n",
    "for i in f:\n",
    "    nbc_avg.append(np.mean(nbc_res[i], axis = 0))\n",
    "    nbc_stdrr.append(np.std(nbc_res[i], axis = 0)/np.sqrt(10))\n",
    "    lr_avg.append(np.mean(lr_res[i], axis = 0))\n",
    "    lr_stdrr.append(np.std(lr_res[i], axis = 0)/np.sqrt(10))\n",
    "    svm_avg.append(np.mean(svm_res[i], axis = 0))\n",
    "    svm_stdrr.append(np.std(svm_res[i], axis = 0)/np.sqrt(10))\n",
    "\n",
    "for i in range(len(f)):\n",
    "    f[i] *= 9 * 529\n",
    "\n",
    "print lr_avg, svm_avg\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(f, nbc_avg, color='red', label='NBC')\n",
    "plt.plot(f, lr_avg, color='green', label='LR')\n",
    "plt.plot(f, svm_avg, color='blue', label='SVM')\n",
    "\n",
    "plt.errorbar(f, nbc_avg, nbc_stdrr, color='red')\n",
    "plt.errorbar(f, lr_avg, lr_stdrr, color='green')\n",
    "plt.errorbar(f, svm_avg, svm_stdrr, color='blue')\n",
    "\n",
    "plt.xlabel(\"t_frac\")\n",
    "plt.ylabel(\"accuracy\");\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=15.415948619949303, pvalue=2.6874121443687926e-08)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(lr_avg, svm_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.24279884431763557, pvalue=0.8130687604827431)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(lr_stdrr, svm_stdrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
