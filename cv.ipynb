{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(scores):\n",
    "    predictions = np.zeros(len(scores))\n",
    "    for i in range(len(predictions)):\n",
    "        if scores[i] >= 0:\n",
    "            predictions[i] +=  1.0 / (1.0 + np.exp(-scores[i]))\n",
    "        else:\n",
    "            predictions[i] += np.exp(scores[i]) / (1.0 + np.exp(scores[i]))\n",
    "    return predictions\n",
    "\n",
    "def lr(trainingSet, testSet):\n",
    "    #print len(trainingSet.columns)\n",
    "    regularization = 0.01\n",
    "    step_size = 0.01\n",
    "    \n",
    "    max_iterations = 500\n",
    "    tol = 1e-6\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    \n",
    "    #print train_labels, trainingSet\n",
    "    w = np.zeros(len(trainingSet.columns) + 1)\n",
    "    \n",
    "    # Add intercept\n",
    "    X = np.array(trainingSet)\n",
    "    Y = np.array(train_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    #X = np.concatenate((X, intercept.T), axis=1)\n",
    "    X = np.hstack((X, intercept))\n",
    "    diff = 100.0\n",
    "    \n",
    "    while(count < max_iterations and diff > tol):\n",
    "        count += 1\n",
    "        norm_old = np.linalg.norm(w)\n",
    "        \n",
    "        scores = np.dot(X, w)\n",
    "        predictions = sigmoid(scores)\n",
    "\n",
    "        gradient = np.dot(X.T, (predictions - Y))\n",
    "\n",
    "        for j in range(len(w)):\n",
    "            gradient[j] += regularization * w[j]\n",
    "            \n",
    "        #gradient /= len(train_labels)\n",
    "        w -= step_size * gradient\n",
    "        norm_new = np.linalg.norm(w)\n",
    "        \n",
    "        diff = abs(norm_new - norm_old)\n",
    "        #print w\n",
    "        #print count, diff\n",
    "    \n",
    "    return w\n",
    "\n",
    "def svm(trainingSet, testSet):\n",
    "    #print len(trainingSet.columns)\n",
    "    regularization = 0.01\n",
    "    step_size = 0.50\n",
    "    \n",
    "    max_iterations = 500\n",
    "    tol = 1e-6\n",
    "    #print len(trainingSet[trainingSet['decision'] == 1])\n",
    "    count = 0\n",
    "    train_labels = trainingSet['decision']    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "\n",
    "    w = np.zeros(len(trainingSet.columns) + 1)\n",
    "    \n",
    "    # Add intercept\n",
    "    X = np.array(trainingSet)\n",
    "    Y = np.array(train_labels)\n",
    "    #print train_labels\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == 0:\n",
    "            Y[i] = -1.0\n",
    "        else:\n",
    "            Y[i] = 1.0\n",
    "    #print Y.tolist()\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((intercept, X))\n",
    "    diff = 100.0\n",
    "    while(count < max_iterations and diff > tol):\n",
    "        count += 1\n",
    "        norm_old = np.linalg.norm(w)\n",
    "        \n",
    "        predictions = np.dot(X, w)\n",
    "    \n",
    "        error = 0\n",
    "        gradient = np.zeros(len(w))\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i] * Y[i] < 1.0:\n",
    "                error += 1\n",
    "                #gradient -= 1.0 * Y[i] * X[i]\n",
    "                gradient -= np.multiply(X[i], Y[i])\n",
    "            \n",
    "        gradient /= 1.0 * len(train_labels)\n",
    "        #print gradient.shape, X[0].shape\n",
    "        \n",
    "        for j in range(1, len(gradient)):\n",
    "            gradient[j] += 1.0 * regularization * w[j]\n",
    "\n",
    "        w -= 1.0 * step_size * gradient\n",
    "        norm_new = np.linalg.norm(w)\n",
    "        diff = abs(norm_new - norm_old)\n",
    "        #print count, diff, error\n",
    "    #print w\n",
    "    return w\n",
    "\n",
    "def nbc(trainingSet, testSet):\n",
    "    attr_list = list(trainingSet[trainingSet.columns.difference(['decision'])])\n",
    "    dict_table ={}\n",
    "    \n",
    "    # Labels\n",
    "    dict_labels = {}\n",
    "    dict_labels['no'] = len(trainingSet[trainingSet['decision'] == 0])\n",
    "    dict_labels['yes'] = len(trainingSet[trainingSet['decision'] == 1])\n",
    "    dict_table['decision'] = dict_labels\n",
    "    \n",
    "    # Attributes in discrete_columns\n",
    "    for attr in attr_list:\n",
    "        dict_attr = {}\n",
    "        attr_bin = max(int(trainingSet[attr].max()), int(testSet[attr].max()))\n",
    "        \n",
    "        dict_attr['no'] = [0 for i in range(attr_bin + 1)]\n",
    "        dict_attr['yes'] = [0 for i in range(attr_bin + 1)]\n",
    "        \n",
    "        for i in range(attr_bin+1):\n",
    "            dict_attr['no'][i] += len(trainingSet[(trainingSet[attr] == i) & (trainingSet['decision'] == 0)])\n",
    "            dict_attr['yes'][i] += len(trainingSet[(trainingSet[attr] == i) & (trainingSet['decision'] == 1)])\n",
    "\n",
    "        dict_table[attr] = dict_attr\n",
    "        \n",
    "    return dict_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_lr(w, trainingSet, testSet):\n",
    "    total_train = len(trainingSet)\n",
    "    count_train = 0\n",
    "    total_test = len(testSet)\n",
    "    count_test = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = np.array(testSet['decision'])\n",
    "    #print test_labels\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    # Test accuracy\n",
    "    X = np.array(testSet)\n",
    "    Y = np.array(test_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((X, intercept))\n",
    "\n",
    "    scores = np.dot(X, w)\n",
    "    predictions = sigmoid(scores)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] > 0.5:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "\n",
    "    for i in range(len(predictions)):    \n",
    "        if predictions[i] == int(Y[i]):\n",
    "            count_test += 1\n",
    "            \n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    print 'Test Accuracy LR:', '%.2f' % test_accuracy\n",
    "    return test_accuracy\n",
    "    \n",
    "def get_accuracy_svm(w, trainingSet, testSet):\n",
    "    total_train = len(trainingSet)\n",
    "    count_train = 0\n",
    "    total_test = len(testSet)\n",
    "    count_test = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = testSet['decision']\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    # Test accuracy\n",
    "    X = np.array(testSet)\n",
    "    Y = np.array(test_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((intercept, X))\n",
    "\n",
    "    predictions = np.dot(X, w)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] > 0.0:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "\n",
    "    for i in range(len(predictions)):    \n",
    "        if predictions[i] == int(Y[i]):\n",
    "            count_test += 1\n",
    "            \n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    print 'Test Accuracy SVM:', '%.2f' % test_accuracy\n",
    "    return test_accuracy\n",
    "\n",
    "def get_accuracy_nbc(dict_table, trainingSet, testSet):\n",
    "    # Accuracy on training data\n",
    "    (row, col) = trainingSet.shape\n",
    "    attr_list = list(trainingSet[trainingSet.columns.difference(['decision'])])\n",
    "    \n",
    "    neg_num = len(trainingSet[trainingSet['decision'] == 0])\n",
    "    pos_num = len(trainingSet[trainingSet['decision'] == 1])\n",
    "    \n",
    "    # Accuracy on test data\n",
    "    (row_test, col_test) = testSet.shape\n",
    "    \n",
    "    row_index_test = testSet.index.tolist()\n",
    "\n",
    "    correct = 0\n",
    "    for i in row_index_test:\n",
    "        pd_pos = 1.0 * dict_table['decision']['yes']/row\n",
    "        pd_neg = 1.0 * dict_table['decision']['no']/row\n",
    "        #print pd_pos, pd_neg\n",
    "        for attr in attr_list:\n",
    "            pd_pos *= 1.0 * dict_table[attr]['yes'][int(testSet[attr][i])]/pos_num\n",
    "            pd_neg *= 1.0 * dict_table[attr]['no'][int(testSet[attr][i])]/neg_num\n",
    "        \n",
    "        res = np.argmax([1.0 * pd_neg, 1.0 * pd_pos])\n",
    "        if res == testSet['decision'][i]:\n",
    "            correct += 1\n",
    "    test_accuracy = 1.0 * correct/row_test\n",
    "    print 'Test Accuracy NBC:', '%.2f' % test_accuracy\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binned_data(bin_value):\n",
    "    df = pd.read_csv('dating-full.csv').head(6500)\n",
    "    #df = pd.head(6500)\n",
    "    (row, col) = df.shape\n",
    "\n",
    "    # strip\n",
    "    df['race'] = df['race'].str.replace(\"'\",\"\")\n",
    "    df['race_o'] = df['race_o'].str.replace(\"'\",\"\")\n",
    "    df['field'] = df['field'].str.replace(\"'\",\"\")\n",
    "    \n",
    "    # lower case\n",
    "    df['field'] = df['field'].str.lower()\n",
    "    \n",
    "    # gender\n",
    "    df['gender'] = df['gender'].astype('category')\n",
    "    df['gender'] = df['gender'].cat.codes    \n",
    "    # race\n",
    "    df['race'] = df['race'].astype('category')\n",
    "    df['race'] = df['race'].cat.codes\n",
    "    #print d['race']    \n",
    "    # race_o\n",
    "    df['race_o'] = df['race_o'].astype('category')\n",
    "    df['race_o'] = df['race_o'].cat.codes    \n",
    "    # field\n",
    "    df['field'] = df['field'].astype('category')\n",
    "    df['field'] = df['field'].cat.codes\n",
    "    \n",
    "    # Normalize the score\n",
    "    preference_scores_of_participant  = \\\n",
    "    ['attractive_important', 'sincere_important', 'intelligence_important',\\\n",
    "     'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "\n",
    "    preference_scores_of_partner = \\\n",
    "    ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', \\\n",
    "     'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\n",
    "\n",
    "    for i in range(row):\n",
    "        participant_sum = 0\n",
    "        partner_sum = 0\n",
    "    \n",
    "        for pref in preference_scores_of_participant:\n",
    "            participant_sum += df[pref][i]\n",
    "            \n",
    "        for pref in preference_scores_of_partner:\n",
    "            partner_sum += df[pref][i]\n",
    "        \n",
    "        # update the preference scores of participant\n",
    "        for pref in preference_scores_of_participant:\n",
    "            df.loc[i, pref] = df[pref][i]/participant_sum\n",
    "            \n",
    "        # update the preference scores of partner\n",
    "        for pref in preference_scores_of_partner:\n",
    "            df.loc[i, pref] = df[pref][i]/partner_sum\n",
    "        \n",
    "    discrete_columns = ['gender', 'race', 'race_o', 'samerace', 'field', 'decision']\n",
    "    all_columns = df.columns.values.tolist()\n",
    "    continuous_valued_columns = [item for item in all_columns if item not in discrete_columns]\n",
    "\n",
    "    (row, col) = df.shape\n",
    "    age_range = [18.0, 58.0]\n",
    "    pref_score = [0.0, 1.0]\n",
    "    score = [0.0, 10.0]\n",
    "    corr_range = [-1.00, 1.00]\n",
    "    \n",
    "    bin_seg = [1.000 * i/bin_value for i in range(0, bin_value + 1)]\n",
    "    #print bin_seg\n",
    "\n",
    "    age = ['age', 'age_o']\n",
    "    corr = ['interests_correlate']\n",
    "    preference_scores_of_participant = \\\n",
    "    ['attractive_important', 'sincere_important', 'intelligence_important',\\\n",
    "     'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "    \n",
    "    preference_scores_of_partner = \\\n",
    "    ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', \\\n",
    "     'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\n",
    "    \n",
    "    continuous_valued_columns_bins = {}\n",
    "    \n",
    "    # Segment the bins\n",
    "    for field in continuous_valued_columns:\n",
    "        continuous_valued_columns_bins[field] = []\n",
    "        if field in age:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(age_range[0] + bin_seg[i] * (age_range[1] - age_range[0]))\n",
    "        elif field in corr:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(corr_range[0] + bin_seg[i] * (corr_range[1] - corr_range[0]))\n",
    "        elif field in preference_scores_of_participant or field in preference_scores_of_partner:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(pref_score[0] + bin_seg[i] * (pref_score[1] - pref_score[0]))\n",
    "        else:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(score[0] + bin_seg[i] * (score[1] - score[0]))\n",
    "    \n",
    "    # Dictionary of the numbers ine ach bin\n",
    "    continuous_valued_columns_seg = {}\n",
    "    # Initalize the dict\n",
    "    for field in continuous_valued_columns:\n",
    "        continuous_valued_columns_seg[field] = [0 for i in range(bin_value)]\n",
    "    \n",
    "    for i in range(row):\n",
    "        for field in continuous_valued_columns:\n",
    "            # Find the bin\n",
    "            for j in range(0, bin_value):\n",
    "                # Corner Case\n",
    "                if j == 0:\n",
    "                    if continuous_valued_columns_bins[field][j] <= float(df[field][i]) <= continuous_valued_columns_bins[field][j + 1]:\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "                elif j == bin_value - 1:\n",
    "                    if continuous_valued_columns_bins[field][j] < float(df[field][i]):\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "                else:\n",
    "                    if continuous_valued_columns_bins[field][j] < float(df[field][i]) <= continuous_valued_columns_bins[field][j + 1]:\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "        \n",
    "    df = df.astype('int64')\n",
    "    df_test = df.sample(frac=0.2, random_state=25)    \n",
    "    # Subtract \n",
    "    df_train = df[~df.index.isin(df_test.index)]\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataFilename = 'trainingSet.csv'\n",
    "testDataFilename = 'testSet.csv'\n",
    "trainingSet = pd.read_csv(trainingDataFilename)\n",
    "testSet = pd.read_csv(testDataFilename)\n",
    "\n",
    "trainingSet_nbc, testSet_nbc = get_binned_data(5)\n",
    "\n",
    "f = [0.025, 0.05, 0.075, 0.1, 0.15, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the training set\n",
    "trainingSet = trainingSet.sample(frac=1, random_state=18)\n",
    "trainingSet_nbc = trainingSet_nbc.sample(frac=1, random_state=18)\n",
    "\n",
    "df_kfold = []\n",
    "for i in range(10):\n",
    "    df_kfold.append(trainingSet[i*520:(i+1)*520])\n",
    "    \n",
    "df_kfold_nbc = []\n",
    "for i in range(10):\n",
    "    df_kfold_nbc.append(trainingSet_nbc[i*520:(i+1)*520])\n",
    "    \n",
    "nbc_res = {}\n",
    "lr_res = {}\n",
    "svm_res = {}\n",
    "\n",
    "for t_frac in f:\n",
    "    nbc_res[t_frac] = []\n",
    "    lr_res[t_frac] = []\n",
    "    svm_res[t_frac] = []\n",
    "#print nbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f = 0.025\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.72\n",
      "Test Accuracy SVM: 0.65\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.61\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.60\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.72\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.58\n",
      "Test Accuracy LR: 0.58\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.58\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.51\n",
      "Test Accuracy NBC: 0.60\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.50\n",
      "Test Accuracy NBC: 0.59\n",
      "Test Accuracy LR: 0.59\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.60\n",
      "f = 0.05\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.48\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.60\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.63\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.61\n",
      "f = 0.075\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.48\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.65\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.65\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "f = 0.1\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.71\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.70\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "f = 0.15\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.70\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.60\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.65\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.69\n",
      "f = 0.2\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.71\n",
      "Test Accuracy SVM: 0.61\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.74\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.72\n"
     ]
    }
   ],
   "source": [
    "for t_frac in f:\n",
    "    print 'f =' , t_frac\n",
    "    for i in range(10):\n",
    "        # Partition the tarin and cv\n",
    "        train_set_df = []\n",
    "        train_set_nbc_df = []\n",
    "        \n",
    "        for j in range(10):\n",
    "            if j != i:\n",
    "                train_set_df.append(df_kfold[j])\n",
    "                train_set_nbc_df.append(df_kfold_nbc[j])\n",
    "            else:\n",
    "                test_set = df_kfold[j]\n",
    "                test_set_nbc = df_kfold_nbc[j]\n",
    "        \n",
    "        train_set = pd.concat(train_set_df).sample(frac=t_frac, random_state=32)\n",
    "        train_set_nbc = pd.concat(train_set_nbc_df).sample(frac=t_frac, random_state=32)\n",
    "        #print train_set\n",
    "        \n",
    "        # Train and Test\n",
    "        w = lr(train_set, test_set)\n",
    "        lr_res[t_frac].append(get_accuracy_lr(w, train_set, test_set))\n",
    "\n",
    "        w = svm(train_set, test_set)\n",
    "        svm_res[t_frac].append(get_accuracy_svm(w, train_set, test_set))\n",
    "        \n",
    "        dict_nbc = nbc(train_set_nbc, test_set_nbc)\n",
    "        nbc_res[t_frac].append(get_accuracy_nbc(dict_nbc, train_set_nbc, test_set_nbc))\n",
    "\n",
    "#print lr_res\n",
    "#print svm_res\n",
    "#print nbc_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = [0.025, 0.05, 0.075, 0.1, 0.15, 0.2]\n",
    "# Get avg accuracy\n",
    "nbc_avg = []\n",
    "lr_avg = []\n",
    "svm_avg = []\n",
    "\n",
    "# Get std error\n",
    "nbc_stdrr = []\n",
    "lr_stdrr = []\n",
    "svm_stdrr = []\n",
    "\n",
    "for i in f:\n",
    "    nbc_avg.append(np.mean(nbc_res[i], axis = 0))\n",
    "    nbc_stdrr.append(np.std(nbc_res[i], axis = 0)/np.sqrt(10))\n",
    "    lr_avg.append(np.mean(lr_res[i], axis = 0))\n",
    "    lr_stdrr.append(np.std(lr_res[i], axis = 0)/np.sqrt(10))\n",
    "    svm_avg.append(np.mean(svm_res[i], axis = 0))\n",
    "    svm_stdrr.append(np.std(svm_res[i], axis = 0)/np.sqrt(10))\n",
    "\n",
    "for i in range(len(f)):\n",
    "    f[i] *= 9 * 529\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(f, nbc_avg, color='red', label='NBC')\n",
    "plt.plot(f, lr_avg, color='yellow', label='LR')\n",
    "plt.plot(f, svm_avg, color='blue', label='SVM')\n",
    "\n",
    "plt.errorbar(f, nbc_avg, nbc_stdrr, color='red')\n",
    "plt.errorbar(f, lr_avg, lr_stdrr, color='yellow')\n",
    "plt.errorbar(f, svm_avg, svm_stdrr, color='blue')\n",
    "\n",
    "plt.xlabel(\"t_frac\")\n",
    "plt.ylabel(\"accuracy\");\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
