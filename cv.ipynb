{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(scores):\n",
    "    predictions = np.zeros(len(scores))\n",
    "    for i in range(len(predictions)):\n",
    "        if scores[i] >= 0:\n",
    "            predictions[i] +=  1.0 / (1.0 + np.exp(-scores[i]))\n",
    "        else:\n",
    "            predictions[i] += np.exp(scores[i]) / (1.0 + np.exp(scores[i]))\n",
    "    return predictions\n",
    "\n",
    "def lr(trainingSet, testSet):\n",
    "    #print len(trainingSet.columns)\n",
    "    regularization = 0.01\n",
    "    step_size = 0.01\n",
    "    \n",
    "    max_iterations = 500\n",
    "    tol = 1e-6\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    \n",
    "    #print train_labels, trainingSet\n",
    "    w = np.zeros(len(trainingSet.columns) + 1)\n",
    "    \n",
    "    # Add intercept\n",
    "    X = np.array(trainingSet)\n",
    "    Y = np.array(train_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    #X = np.concatenate((X, intercept.T), axis=1)\n",
    "    X = np.hstack((X, intercept))\n",
    "    diff = 100.0\n",
    "    \n",
    "    while(count < max_iterations and diff > tol):\n",
    "        count += 1\n",
    "        norm_old = np.linalg.norm(w)\n",
    "        \n",
    "        scores = np.dot(X, w)\n",
    "        predictions = sigmoid(scores)\n",
    "\n",
    "        gradient = np.dot(X.T, (predictions - Y))\n",
    "\n",
    "        for j in range(len(w)):\n",
    "            gradient[j] += regularization * w[j]\n",
    "            \n",
    "        #gradient /= len(train_labels)\n",
    "        w -= step_size * gradient\n",
    "        norm_new = np.linalg.norm(w)\n",
    "        \n",
    "        diff = abs(norm_new - norm_old)\n",
    "        #print w\n",
    "        #print count, diff\n",
    "    \n",
    "    return w\n",
    "\n",
    "def svm(trainingSet, testSet):\n",
    "    #print len(trainingSet.columns)\n",
    "    regularization = 0.01\n",
    "    step_size = 0.50\n",
    "    \n",
    "    max_iterations = 500\n",
    "    tol = 1e-6\n",
    "    #print len(trainingSet[trainingSet['decision'] == 1])\n",
    "    count = 0\n",
    "    train_labels = trainingSet['decision']    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "\n",
    "    w = np.zeros(len(trainingSet.columns) + 1)\n",
    "    \n",
    "    # Add intercept\n",
    "    X = np.array(trainingSet)\n",
    "    Y = np.array(train_labels)\n",
    "    #print train_labels\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == 0:\n",
    "            Y[i] = -1.0\n",
    "        else:\n",
    "            Y[i] = 1.0\n",
    "    #print Y.tolist()\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((intercept, X))\n",
    "    diff = 100.0\n",
    "    while(count < max_iterations and diff > tol):\n",
    "        count += 1\n",
    "        norm_old = np.linalg.norm(w)\n",
    "        \n",
    "        predictions = np.dot(X, w)\n",
    "    \n",
    "        error = 0\n",
    "        gradient = np.zeros(len(w))\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i] * Y[i] < 1.0:\n",
    "                error += 1\n",
    "                #gradient -= 1.0 * Y[i] * X[i]\n",
    "                gradient -= np.multiply(X[i], Y[i])\n",
    "            \n",
    "        gradient /= 1.0 * len(train_labels)\n",
    "        #print gradient.shape, X[0].shape\n",
    "        \n",
    "        for j in range(1, len(gradient)):\n",
    "            gradient[j] += 1.0 * regularization * w[j]\n",
    "\n",
    "        w -= 1.0 * step_size * gradient\n",
    "        norm_new = np.linalg.norm(w)\n",
    "        diff = abs(norm_new - norm_old)\n",
    "        #print count, diff, error\n",
    "    #print w\n",
    "    return w\n",
    "\n",
    "def nbc(trainingSet, testSet):\n",
    "    attr_list = list(trainingSet[trainingSet.columns.difference(['decision'])])\n",
    "    dict_table ={}\n",
    "    \n",
    "    # Labels\n",
    "    dict_labels = {}\n",
    "    dict_labels['no'] = len(trainingSet[trainingSet['decision'] == 0])\n",
    "    dict_labels['yes'] = len(trainingSet[trainingSet['decision'] == 1])\n",
    "    dict_table['decision'] = dict_labels\n",
    "    \n",
    "    # Attributes in discrete_columns\n",
    "    for attr in attr_list:\n",
    "        dict_attr = {}\n",
    "        attr_bin = max(int(trainingSet[attr].max()), int(testSet[attr].max()))\n",
    "        \n",
    "        dict_attr['no'] = [0 for i in range(attr_bin + 1)]\n",
    "        dict_attr['yes'] = [0 for i in range(attr_bin + 1)]\n",
    "        \n",
    "        for i in range(attr_bin+1):\n",
    "            dict_attr['no'][i] += len(trainingSet[(trainingSet[attr] == i) & (trainingSet['decision'] == 0)])\n",
    "            dict_attr['yes'][i] += len(trainingSet[(trainingSet[attr] == i) & (trainingSet['decision'] == 1)])\n",
    "\n",
    "        dict_table[attr] = dict_attr\n",
    "        \n",
    "    return dict_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_lr(w, trainingSet, testSet):\n",
    "    total_train = len(trainingSet)\n",
    "    count_train = 0\n",
    "    total_test = len(testSet)\n",
    "    count_test = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = np.array(testSet['decision'])\n",
    "    #print test_labels\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    # Test accuracy\n",
    "    X = np.array(testSet)\n",
    "    Y = np.array(test_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((X, intercept))\n",
    "\n",
    "    scores = np.dot(X, w)\n",
    "    predictions = sigmoid(scores)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] > 0.5:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "\n",
    "    for i in range(len(predictions)):    \n",
    "        if predictions[i] == int(Y[i]):\n",
    "            count_test += 1\n",
    "            \n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    print 'Test Accuracy LR:', '%.2f' % test_accuracy\n",
    "    return test_accuracy\n",
    "    \n",
    "def get_accuracy_svm(w, trainingSet, testSet):\n",
    "    total_train = len(trainingSet)\n",
    "    count_train = 0\n",
    "    total_test = len(testSet)\n",
    "    count_test = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = testSet['decision']\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    # Test accuracy\n",
    "    X = np.array(testSet)\n",
    "    Y = np.array(test_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((intercept, X))\n",
    "\n",
    "    predictions = np.dot(X, w)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] > 0.0:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "\n",
    "    for i in range(len(predictions)):    \n",
    "        if predictions[i] == int(Y[i]):\n",
    "            count_test += 1\n",
    "            \n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    print 'Test Accuracy SVM:', '%.2f' % test_accuracy\n",
    "    return test_accuracy\n",
    "\n",
    "def get_accuracy_nbc(dict_table, trainingSet, testSet):\n",
    "    # Accuracy on training data\n",
    "    (row, col) = trainingSet.shape\n",
    "    attr_list = list(trainingSet[trainingSet.columns.difference(['decision'])])\n",
    "    \n",
    "    neg_num = len(trainingSet[trainingSet['decision'] == 0])\n",
    "    pos_num = len(trainingSet[trainingSet['decision'] == 1])\n",
    "    \n",
    "    # Accuracy on test data\n",
    "    (row_test, col_test) = testSet.shape\n",
    "    \n",
    "    row_index_test = testSet.index.tolist()\n",
    "\n",
    "    correct = 0\n",
    "    for i in row_index_test:\n",
    "        pd_pos = 1.0 * dict_table['decision']['yes']/row\n",
    "        pd_neg = 1.0 * dict_table['decision']['no']/row\n",
    "        #print pd_pos, pd_neg\n",
    "        for attr in attr_list:\n",
    "            pd_pos *= 1.0 * dict_table[attr]['yes'][int(testSet[attr][i])]/pos_num\n",
    "            pd_neg *= 1.0 * dict_table[attr]['no'][int(testSet[attr][i])]/neg_num\n",
    "        \n",
    "        res = np.argmax([1.0 * pd_neg, 1.0 * pd_pos])\n",
    "        if res == testSet['decision'][i]:\n",
    "            correct += 1\n",
    "    test_accuracy = 1.0 * correct/row_test\n",
    "    print 'Test Accuracy NBC:', '%.2f' % test_accuracy\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binned_data(bin_value):\n",
    "    df = pd.read_csv('dating-full.csv').head(6500)\n",
    "    #df = pd.head(6500)\n",
    "    (row, col) = df.shape\n",
    "\n",
    "    # strip\n",
    "    df['race'] = df['race'].str.replace(\"'\",\"\")\n",
    "    df['race_o'] = df['race_o'].str.replace(\"'\",\"\")\n",
    "    df['field'] = df['field'].str.replace(\"'\",\"\")\n",
    "    \n",
    "    # lower case\n",
    "    df['field'] = df['field'].str.lower()\n",
    "    \n",
    "    # gender\n",
    "    df['gender'] = df['gender'].astype('category')\n",
    "    df['gender'] = df['gender'].cat.codes    \n",
    "    # race\n",
    "    df['race'] = df['race'].astype('category')\n",
    "    df['race'] = df['race'].cat.codes\n",
    "    #print d['race']    \n",
    "    # race_o\n",
    "    df['race_o'] = df['race_o'].astype('category')\n",
    "    df['race_o'] = df['race_o'].cat.codes    \n",
    "    # field\n",
    "    df['field'] = df['field'].astype('category')\n",
    "    df['field'] = df['field'].cat.codes\n",
    "    \n",
    "    # Normalize the score\n",
    "    preference_scores_of_participant  = \\\n",
    "    ['attractive_important', 'sincere_important', 'intelligence_important',\\\n",
    "     'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "\n",
    "    preference_scores_of_partner = \\\n",
    "    ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', \\\n",
    "     'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\n",
    "\n",
    "    for i in range(row):\n",
    "        participant_sum = 0\n",
    "        partner_sum = 0\n",
    "    \n",
    "        for pref in preference_scores_of_participant:\n",
    "            participant_sum += df[pref][i]\n",
    "            \n",
    "        for pref in preference_scores_of_partner:\n",
    "            partner_sum += df[pref][i]\n",
    "        \n",
    "        # update the preference scores of participant\n",
    "        for pref in preference_scores_of_participant:\n",
    "            df.loc[i, pref] = df[pref][i]/participant_sum\n",
    "            \n",
    "        # update the preference scores of partner\n",
    "        for pref in preference_scores_of_partner:\n",
    "            df.loc[i, pref] = df[pref][i]/partner_sum\n",
    "        \n",
    "    discrete_columns = ['gender', 'race', 'race_o', 'samerace', 'field', 'decision']\n",
    "    all_columns = df.columns.values.tolist()\n",
    "    continuous_valued_columns = [item for item in all_columns if item not in discrete_columns]\n",
    "\n",
    "    (row, col) = df.shape\n",
    "    age_range = [18.0, 58.0]\n",
    "    pref_score = [0.0, 1.0]\n",
    "    score = [0.0, 10.0]\n",
    "    corr_range = [-1.00, 1.00]\n",
    "    \n",
    "    bin_seg = [1.000 * i/bin_value for i in range(0, bin_value + 1)]\n",
    "    #print bin_seg\n",
    "\n",
    "    age = ['age', 'age_o']\n",
    "    corr = ['interests_correlate']\n",
    "    preference_scores_of_participant = \\\n",
    "    ['attractive_important', 'sincere_important', 'intelligence_important',\\\n",
    "     'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "    \n",
    "    preference_scores_of_partner = \\\n",
    "    ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', \\\n",
    "     'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\n",
    "    \n",
    "    continuous_valued_columns_bins = {}\n",
    "    \n",
    "    # Segment the bins\n",
    "    for field in continuous_valued_columns:\n",
    "        continuous_valued_columns_bins[field] = []\n",
    "        if field in age:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(age_range[0] + bin_seg[i] * (age_range[1] - age_range[0]))\n",
    "        elif field in corr:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(corr_range[0] + bin_seg[i] * (corr_range[1] - corr_range[0]))\n",
    "        elif field in preference_scores_of_participant or field in preference_scores_of_partner:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(pref_score[0] + bin_seg[i] * (pref_score[1] - pref_score[0]))\n",
    "        else:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(score[0] + bin_seg[i] * (score[1] - score[0]))\n",
    "    \n",
    "    # Dictionary of the numbers ine ach bin\n",
    "    continuous_valued_columns_seg = {}\n",
    "    # Initalize the dict\n",
    "    for field in continuous_valued_columns:\n",
    "        continuous_valued_columns_seg[field] = [0 for i in range(bin_value)]\n",
    "    \n",
    "    for i in range(row):\n",
    "        for field in continuous_valued_columns:\n",
    "            # Find the bin\n",
    "            for j in range(0, bin_value):\n",
    "                # Corner Case\n",
    "                if j == 0:\n",
    "                    if continuous_valued_columns_bins[field][j] <= float(df[field][i]) <= continuous_valued_columns_bins[field][j + 1]:\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "                elif j == bin_value - 1:\n",
    "                    if continuous_valued_columns_bins[field][j] < float(df[field][i]):\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "                else:\n",
    "                    if continuous_valued_columns_bins[field][j] < float(df[field][i]) <= continuous_valued_columns_bins[field][j + 1]:\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "        \n",
    "    df = df.astype('int64')\n",
    "    df_test = df.sample(frac=0.2, random_state=25)    \n",
    "    # Subtract \n",
    "    df_train = df[~df.index.isin(df_test.index)]\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataFilename = 'trainingSet.csv'\n",
    "testDataFilename = 'testSet.csv'\n",
    "trainingSet = pd.read_csv(trainingDataFilename)\n",
    "testSet = pd.read_csv(testDataFilename)\n",
    "\n",
    "trainingSet_nbc, testSet_nbc = get_binned_data(5)\n",
    "\n",
    "f = [0.025, 0.05, 0.075, 0.1, 0.15, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the training set\n",
    "trainingSet = trainingSet.sample(frac=1, random_state=18)\n",
    "trainingSet_nbc = trainingSet_nbc.sample(frac=1, random_state=18)\n",
    "\n",
    "df_kfold = []\n",
    "for i in range(10):\n",
    "    df_kfold.append(trainingSet[i*520:(i+1)*520])\n",
    "    \n",
    "df_kfold_nbc = []\n",
    "for i in range(10):\n",
    "    df_kfold_nbc.append(trainingSet_nbc[i*520:(i+1)*520])\n",
    "    \n",
    "nbc_res = {}\n",
    "lr_res = {}\n",
    "svm_res = {}\n",
    "\n",
    "for t_frac in f:\n",
    "    nbc_res[t_frac] = []\n",
    "    lr_res[t_frac] = []\n",
    "    svm_res[t_frac] = []\n",
    "#print nbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f = 0.025\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.72\n",
      "Test Accuracy SVM: 0.65\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.61\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.60\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.72\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.58\n",
      "Test Accuracy LR: 0.58\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.58\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.51\n",
      "Test Accuracy NBC: 0.60\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.50\n",
      "Test Accuracy NBC: 0.59\n",
      "Test Accuracy LR: 0.59\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.60\n",
      "f = 0.05\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.48\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.60\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.63\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.61\n",
      "f = 0.075\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.48\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.65\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.65\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "f = 0.1\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.71\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.70\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "f = 0.15\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.70\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.60\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.65\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.69\n",
      "f = 0.2\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.71\n",
      "Test Accuracy SVM: 0.61\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.74\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.72\n"
     ]
    }
   ],
   "source": [
    "for t_frac in f:\n",
    "    print 'f =' , t_frac\n",
    "    for i in range(10):\n",
    "        # Partition the tarin and cv\n",
    "        train_set_df = []\n",
    "        train_set_nbc_df = []\n",
    "        \n",
    "        for j in range(10):\n",
    "            if j != i:\n",
    "                train_set_df.append(df_kfold[j])\n",
    "                train_set_nbc_df.append(df_kfold_nbc[j])\n",
    "            else:\n",
    "                test_set = df_kfold[j]\n",
    "                test_set_nbc = df_kfold_nbc[j]\n",
    "        \n",
    "        train_set = pd.concat(train_set_df).sample(frac=t_frac, random_state=32)\n",
    "        train_set_nbc = pd.concat(train_set_nbc_df).sample(frac=t_frac, random_state=32)\n",
    "        #print train_set\n",
    "        \n",
    "        # Train and Test\n",
    "        w = lr(train_set, test_set)\n",
    "        lr_res[t_frac].append(get_accuracy_lr(w, train_set, test_set))\n",
    "\n",
    "        w = svm(train_set, test_set)\n",
    "        svm_res[t_frac].append(get_accuracy_svm(w, train_set, test_set))\n",
    "        \n",
    "        dict_nbc = nbc(train_set_nbc, test_set_nbc)\n",
    "        nbc_res[t_frac].append(get_accuracy_nbc(dict_nbc, train_set_nbc, test_set_nbc))\n",
    "\n",
    "#print lr_res\n",
    "#print svm_res\n",
    "#print nbc_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6540384615384616, 0.6476923076923077, 0.6609615384615385, 0.6819230769230769, 0.6509615384615385, 0.6573076923076921] [0.5567307692307691, 0.5521153846153847, 0.5590384615384615, 0.5655769230769232, 0.5767307692307692, 0.5690384615384615]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = [0.025, 0.05, 0.075, 0.1, 0.15, 0.2]\n",
    "# Get avg accuracy\n",
    "nbc_avg = []\n",
    "lr_avg = []\n",
    "svm_avg = []\n",
    "\n",
    "# Get std error\n",
    "nbc_stdrr = []\n",
    "lr_stdrr = []\n",
    "svm_stdrr = []\n",
    "\n",
    "for i in f:\n",
    "    nbc_avg.append(np.mean(nbc_res[i], axis = 0))\n",
    "    nbc_stdrr.append(np.std(nbc_res[i], axis = 0)/np.sqrt(10))\n",
    "    lr_avg.append(np.mean(lr_res[i], axis = 0))\n",
    "    lr_stdrr.append(np.std(lr_res[i], axis = 0)/np.sqrt(10))\n",
    "    svm_avg.append(np.mean(svm_res[i], axis = 0))\n",
    "    svm_stdrr.append(np.std(svm_res[i], axis = 0)/np.sqrt(10))\n",
    "\n",
    "for i in range(len(f)):\n",
    "    f[i] *= 9 * 529\n",
    "\n",
    "print lr_avg, svm_avg\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(f, nbc_avg, color='red', label='NBC')\n",
    "plt.plot(f, lr_avg, color='yellow', label='LR')\n",
    "plt.plot(f, svm_avg, color='blue', label='SVM')\n",
    "\n",
    "plt.errorbar(f, nbc_avg, nbc_stdrr, color='red')\n",
    "plt.errorbar(f, lr_avg, lr_stdrr, color='green')\n",
    "plt.errorbar(f, svm_avg, svm_stdrr, color='blue')\n",
    "\n",
    "plt.xlabel(\"t_frac\")\n",
    "plt.ylabel(\"accuracy\");\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-5.873654712445049, pvalue=0.0001565214405540783)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(svm_avg, nbc_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
