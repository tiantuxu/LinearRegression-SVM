{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(scores):\n",
    "    predictions = np.zeros(len(scores))\n",
    "    for i in range(len(predictions)):\n",
    "        if scores[i] >= 0:\n",
    "            predictions[i] +=  1.0 / (1.0 + np.exp(-scores[i]))\n",
    "        else:\n",
    "            predictions[i] += np.exp(scores[i]) / (1.0 + np.exp(scores[i]))\n",
    "    return predictions\n",
    "\n",
    "def lr(trainingSet, testSet):\n",
    "    #print len(trainingSet.columns)\n",
    "    regularization = 0.01\n",
    "    step_size = 0.01\n",
    "    \n",
    "    max_iterations = 500\n",
    "    tol = 1e-6\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    \n",
    "    #print train_labels, trainingSet\n",
    "    w = np.zeros(len(trainingSet.columns) + 1)\n",
    "    \n",
    "    # Add intercept\n",
    "    X = np.array(trainingSet)\n",
    "    Y = np.array(train_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    #X = np.concatenate((X, intercept.T), axis=1)\n",
    "    X = np.hstack((X, intercept))\n",
    "    diff = 100.0\n",
    "    \n",
    "    while(count < max_iterations and diff > tol):\n",
    "        count += 1\n",
    "        norm_old = np.linalg.norm(w)\n",
    "        \n",
    "        scores = np.dot(X, w)\n",
    "        predictions = sigmoid(scores)\n",
    "\n",
    "        gradient = np.dot(X.T, (predictions - Y))\n",
    "\n",
    "        for j in range(len(w)):\n",
    "            gradient[j] += regularization * w[j]\n",
    "            \n",
    "        #gradient /= len(train_labels)\n",
    "        w -= step_size * gradient\n",
    "        norm_new = np.linalg.norm(w)\n",
    "        \n",
    "        diff = abs(norm_new - norm_old)\n",
    "        #print w\n",
    "        #print count, diff\n",
    "    \n",
    "    return w\n",
    "\n",
    "def svm(trainingSet, testSet):\n",
    "    #print len(trainingSet.columns)\n",
    "    regularization = 0.01\n",
    "    step_size = 0.50\n",
    "    \n",
    "    max_iterations = 500\n",
    "    tol = 1e-6\n",
    "    #print len(trainingSet[trainingSet['decision'] == 1])\n",
    "    count = 0\n",
    "    train_labels = trainingSet['decision']    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "\n",
    "    w = np.zeros(len(trainingSet.columns) + 1)\n",
    "    \n",
    "    # Add intercept\n",
    "    X = np.array(trainingSet)\n",
    "    Y = np.array(train_labels)\n",
    "    #print train_labels\n",
    "    for i in range(len(Y)):\n",
    "        if Y[i] == 0:\n",
    "            Y[i] = -1.0\n",
    "        else:\n",
    "            Y[i] = 1.0\n",
    "    #print Y.tolist()\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((intercept, X))\n",
    "    diff = 100.0\n",
    "    while(count < max_iterations and diff > tol):\n",
    "        count += 1\n",
    "        norm_old = np.linalg.norm(w)\n",
    "        \n",
    "        predictions = np.dot(X, w)\n",
    "    \n",
    "        error = 0\n",
    "        gradient = np.zeros(len(w))\n",
    "        for i in range(len(predictions)):\n",
    "            if predictions[i] * Y[i] < 1.0:\n",
    "                error += 1\n",
    "                #gradient -= 1.0 * Y[i] * X[i]\n",
    "                gradient -= np.multiply(X[i], Y[i])\n",
    "            \n",
    "        gradient /= 1.0 * len(train_labels)\n",
    "        #print gradient.shape, X[0].shape\n",
    "        \n",
    "        for j in range(1, len(gradient)):\n",
    "            gradient[j] += 1.0 * regularization * w[j]\n",
    "\n",
    "        w -= 1.0 * step_size * gradient\n",
    "        norm_new = np.linalg.norm(w)\n",
    "        diff = abs(norm_new - norm_old)\n",
    "        #print count, diff, error\n",
    "    #print w\n",
    "    return w\n",
    "\n",
    "def nbc(trainingSet, testSet):\n",
    "    attr_list = list(trainingSet[trainingSet.columns.difference(['decision'])])\n",
    "    dict_table ={}\n",
    "    \n",
    "    # Labels\n",
    "    dict_labels = {}\n",
    "    dict_labels['no'] = len(trainingSet[trainingSet['decision'] == 0])\n",
    "    dict_labels['yes'] = len(trainingSet[trainingSet['decision'] == 1])\n",
    "    dict_table['decision'] = dict_labels\n",
    "    \n",
    "    # Attributes in discrete_columns\n",
    "    for attr in attr_list:\n",
    "        dict_attr = {}\n",
    "        attr_bin = max(int(trainingSet[attr].max()), int(testSet[attr].max()))\n",
    "        \n",
    "        dict_attr['no'] = [0 for i in range(attr_bin + 1)]\n",
    "        dict_attr['yes'] = [0 for i in range(attr_bin + 1)]\n",
    "        \n",
    "        for i in range(attr_bin+1):\n",
    "            dict_attr['no'][i] += len(trainingSet[(trainingSet[attr] == i) & (trainingSet['decision'] == 0)])\n",
    "            dict_attr['yes'][i] += len(trainingSet[(trainingSet[attr] == i) & (trainingSet['decision'] == 1)])\n",
    "\n",
    "        dict_table[attr] = dict_attr\n",
    "        \n",
    "    return dict_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_lr(w, trainingSet, testSet):\n",
    "    total_train = len(trainingSet)\n",
    "    count_train = 0\n",
    "    total_test = len(testSet)\n",
    "    count_test = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = np.array(testSet['decision'])\n",
    "    #print test_labels\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    # Test accuracy\n",
    "    X = np.array(testSet)\n",
    "    Y = np.array(test_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((X, intercept))\n",
    "\n",
    "    scores = np.dot(X, w)\n",
    "    predictions = sigmoid(scores)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] > 0.5:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "\n",
    "    for i in range(len(predictions)):    \n",
    "        if predictions[i] == int(Y[i]):\n",
    "            count_test += 1\n",
    "            \n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    #print 'Test Accuracy LR:', '%.2f' % test_accuracy\n",
    "    return test_accuracy\n",
    "    \n",
    "def get_accuracy_svm(w, trainingSet, testSet):\n",
    "    total_train = len(trainingSet)\n",
    "    count_train = 0\n",
    "    total_test = len(testSet)\n",
    "    count_test = 0\n",
    "    \n",
    "    train_labels = trainingSet['decision']\n",
    "    test_labels = testSet['decision']\n",
    "    \n",
    "    trainingSet = trainingSet.drop('decision', axis=1)\n",
    "    testSet = testSet.drop('decision', axis=1)\n",
    "    \n",
    "    # Test accuracy\n",
    "    X = np.array(testSet)\n",
    "    Y = np.array(test_labels)\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    X = np.hstack((intercept, X))\n",
    "\n",
    "    predictions = np.dot(X, w)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] > 0.0:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "\n",
    "    for i in range(len(predictions)):    \n",
    "        if predictions[i] == int(Y[i]):\n",
    "            count_test += 1\n",
    "            \n",
    "    test_accuracy = 1.0 * count_test/total_test\n",
    "    #print 'Test Accuracy SVM:', '%.2f' % test_accuracy\n",
    "    return test_accuracy\n",
    "\n",
    "def get_accuracy_nbc(dict_table, trainingSet, testSet):\n",
    "    # Accuracy on training data\n",
    "    (row, col) = trainingSet.shape\n",
    "    attr_list = list(trainingSet[trainingSet.columns.difference(['decision'])])\n",
    "    \n",
    "    neg_num = len(trainingSet[trainingSet['decision'] == 0])\n",
    "    pos_num = len(trainingSet[trainingSet['decision'] == 1])\n",
    "    \n",
    "    # Accuracy on test data\n",
    "    (row_test, col_test) = testSet.shape\n",
    "    \n",
    "    row_index_test = testSet.index.tolist()\n",
    "\n",
    "    correct = 0\n",
    "    for i in row_index_test:\n",
    "        pd_pos = 1.0 * dict_table['decision']['yes']/row\n",
    "        pd_neg = 1.0 * dict_table['decision']['no']/row\n",
    "        #print pd_pos, pd_neg\n",
    "        for attr in attr_list:\n",
    "            pd_pos *= 1.0 * dict_table[attr]['yes'][int(testSet[attr][i])]/pos_num\n",
    "            pd_neg *= 1.0 * dict_table[attr]['no'][int(testSet[attr][i])]/neg_num\n",
    "        \n",
    "        res = np.argmax([1.0 * pd_neg, 1.0 * pd_pos])\n",
    "        if res == testSet['decision'][i]:\n",
    "            correct += 1\n",
    "    test_accuracy = 1.0 * correct/row_test\n",
    "    #print 'Test Accuracy NBC:', '%.2f' % test_accuracy\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binned_data(bin_value):\n",
    "    df = pd.read_csv('dating-full.csv').head(6500)\n",
    "    #df = pd.head(6500)\n",
    "    (row, col) = df.shape\n",
    "\n",
    "    # strip\n",
    "    df['race'] = df['race'].str.replace(\"'\",\"\")\n",
    "    df['race_o'] = df['race_o'].str.replace(\"'\",\"\")\n",
    "    df['field'] = df['field'].str.replace(\"'\",\"\")\n",
    "    \n",
    "    # lower case\n",
    "    df['field'] = df['field'].str.lower()\n",
    "    \n",
    "    # gender\n",
    "    df['gender'] = df['gender'].astype('category')\n",
    "    df['gender'] = df['gender'].cat.codes    \n",
    "    # race\n",
    "    df['race'] = df['race'].astype('category')\n",
    "    df['race'] = df['race'].cat.codes\n",
    "    #print d['race']    \n",
    "    # race_o\n",
    "    df['race_o'] = df['race_o'].astype('category')\n",
    "    df['race_o'] = df['race_o'].cat.codes    \n",
    "    # field\n",
    "    df['field'] = df['field'].astype('category')\n",
    "    df['field'] = df['field'].cat.codes\n",
    "    \n",
    "    # Normalize the score\n",
    "    preference_scores_of_participant  = \\\n",
    "    ['attractive_important', 'sincere_important', 'intelligence_important',\\\n",
    "     'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "\n",
    "    preference_scores_of_partner = \\\n",
    "    ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', \\\n",
    "     'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\n",
    "\n",
    "    for i in range(row):\n",
    "        participant_sum = 0\n",
    "        partner_sum = 0\n",
    "    \n",
    "        for pref in preference_scores_of_participant:\n",
    "            participant_sum += df[pref][i]\n",
    "            \n",
    "        for pref in preference_scores_of_partner:\n",
    "            partner_sum += df[pref][i]\n",
    "        \n",
    "        # update the preference scores of participant\n",
    "        for pref in preference_scores_of_participant:\n",
    "            df.loc[i, pref] = df[pref][i]/participant_sum\n",
    "            \n",
    "        # update the preference scores of partner\n",
    "        for pref in preference_scores_of_partner:\n",
    "            df.loc[i, pref] = df[pref][i]/partner_sum\n",
    "        \n",
    "    discrete_columns = ['gender', 'race', 'race_o', 'samerace', 'field', 'decision']\n",
    "    all_columns = df.columns.values.tolist()\n",
    "    continuous_valued_columns = [item for item in all_columns if item not in discrete_columns]\n",
    "\n",
    "    (row, col) = df.shape\n",
    "    age_range = [18.0, 58.0]\n",
    "    pref_score = [0.0, 1.0]\n",
    "    score = [0.0, 10.0]\n",
    "    corr_range = [-1.00, 1.00]\n",
    "    \n",
    "    bin_seg = [1.000 * i/bin_value for i in range(0, bin_value + 1)]\n",
    "    #print bin_seg\n",
    "\n",
    "    age = ['age', 'age_o']\n",
    "    corr = ['interests_correlate']\n",
    "    preference_scores_of_participant = \\\n",
    "    ['attractive_important', 'sincere_important', 'intelligence_important',\\\n",
    "     'funny_important', 'ambition_important', 'shared_interests_important']\n",
    "    \n",
    "    preference_scores_of_partner = \\\n",
    "    ['pref_o_attractive', 'pref_o_sincere', 'pref_o_intelligence', \\\n",
    "     'pref_o_funny', 'pref_o_ambitious', 'pref_o_shared_interests']\n",
    "    \n",
    "    continuous_valued_columns_bins = {}\n",
    "    \n",
    "    # Segment the bins\n",
    "    for field in continuous_valued_columns:\n",
    "        continuous_valued_columns_bins[field] = []\n",
    "        if field in age:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(age_range[0] + bin_seg[i] * (age_range[1] - age_range[0]))\n",
    "        elif field in corr:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(corr_range[0] + bin_seg[i] * (corr_range[1] - corr_range[0]))\n",
    "        elif field in preference_scores_of_participant or field in preference_scores_of_partner:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(pref_score[0] + bin_seg[i] * (pref_score[1] - pref_score[0]))\n",
    "        else:\n",
    "            for i in range(0, bin_value):\n",
    "                continuous_valued_columns_bins[field].append(score[0] + bin_seg[i] * (score[1] - score[0]))\n",
    "    \n",
    "    # Dictionary of the numbers ine ach bin\n",
    "    continuous_valued_columns_seg = {}\n",
    "    # Initalize the dict\n",
    "    for field in continuous_valued_columns:\n",
    "        continuous_valued_columns_seg[field] = [0 for i in range(bin_value)]\n",
    "    \n",
    "    for i in range(row):\n",
    "        for field in continuous_valued_columns:\n",
    "            # Find the bin\n",
    "            for j in range(0, bin_value):\n",
    "                # Corner Case\n",
    "                if j == 0:\n",
    "                    if continuous_valued_columns_bins[field][j] <= float(df[field][i]) <= continuous_valued_columns_bins[field][j + 1]:\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "                elif j == bin_value - 1:\n",
    "                    if continuous_valued_columns_bins[field][j] < float(df[field][i]):\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "                else:\n",
    "                    if continuous_valued_columns_bins[field][j] < float(df[field][i]) <= continuous_valued_columns_bins[field][j + 1]:\n",
    "                        df.loc[i,field] = int(j)\n",
    "                        continuous_valued_columns_seg[field][j] += 1\n",
    "                        break\n",
    "        \n",
    "    df = df.astype('int64')\n",
    "    df_test = df.sample(frac=0.2, random_state=25)    \n",
    "    # Subtract \n",
    "    df_train = df[~df.index.isin(df_test.index)]\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDataFilename = 'trainingSet.csv'\n",
    "testDataFilename = 'testSet.csv'\n",
    "trainingSet = pd.read_csv(trainingDataFilename)\n",
    "testSet = pd.read_csv(testDataFilename)\n",
    "\n",
    "trainingSet_nbc, testSet_nbc = get_binned_data(5)\n",
    "\n",
    "f = [0.025, 0.05, 0.075, 0.1, 0.15, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample the training set\n",
    "trainingSet = trainingSet.sample(frac=1, random_state=18)\n",
    "trainingSet_nbc = trainingSet_nbc.sample(frac=1, random_state=18)\n",
    "\n",
    "df_kfold = []\n",
    "for i in range(10):\n",
    "    df_kfold.append(trainingSet[i*520:(i+1)*520])\n",
    "    \n",
    "df_kfold_nbc = []\n",
    "for i in range(10):\n",
    "    df_kfold_nbc.append(trainingSet_nbc[i*520:(i+1)*520])\n",
    "    \n",
    "nbc_res = {}\n",
    "lr_res = {}\n",
    "svm_res = {}\n",
    "\n",
    "for t_frac in f:\n",
    "    nbc_res[t_frac] = []\n",
    "    lr_res[t_frac] = []\n",
    "    svm_res[t_frac] = []\n",
    "#print nbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f = 0.025\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.72\n",
      "Test Accuracy SVM: 0.65\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.61\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.60\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.72\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.58\n",
      "Test Accuracy LR: 0.58\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.58\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.51\n",
      "Test Accuracy NBC: 0.60\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.50\n",
      "Test Accuracy NBC: 0.59\n",
      "Test Accuracy LR: 0.59\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.60\n",
      "f = 0.05\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.48\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.62\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.60\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.61\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.63\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.61\n",
      "f = 0.075\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.48\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.64\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.53\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.62\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.65\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.65\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "f = 0.1\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.70\n",
      "Test Accuracy SVM: 0.52\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.66\n",
      "Test Accuracy LR: 0.71\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.65\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.70\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.66\n",
      "f = 0.15\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.70\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.60\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.65\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.67\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.69\n",
      "f = 0.2\n",
      "Test Accuracy LR: 0.67\n",
      "Test Accuracy SVM: 0.54\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.71\n",
      "Test Accuracy SVM: 0.61\n",
      "Test Accuracy NBC: 0.69\n",
      "Test Accuracy LR: 0.68\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.68\n",
      "Test Accuracy LR: 0.69\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.59\n",
      "Test Accuracy NBC: 0.74\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.57\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.61\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.71\n",
      "Test Accuracy LR: 0.66\n",
      "Test Accuracy SVM: 0.58\n",
      "Test Accuracy NBC: 0.72\n",
      "Test Accuracy LR: 0.63\n",
      "Test Accuracy SVM: 0.55\n",
      "Test Accuracy NBC: 0.73\n",
      "Test Accuracy LR: 0.64\n",
      "Test Accuracy SVM: 0.56\n",
      "Test Accuracy NBC: 0.72\n"
     ]
    }
   ],
   "source": [
    "for t_frac in f:\n",
    "    #print 'f =' , t_frac\n",
    "    for i in range(10):\n",
    "        # Partition the tarin and cv\n",
    "        train_set_df = []\n",
    "        train_set_nbc_df = []\n",
    "        \n",
    "        for j in range(10):\n",
    "            if j != i:\n",
    "                train_set_df.append(df_kfold[j])\n",
    "                train_set_nbc_df.append(df_kfold_nbc[j])\n",
    "            else:\n",
    "                test_set = df_kfold[j]\n",
    "                test_set_nbc = df_kfold_nbc[j]\n",
    "        \n",
    "        train_set = pd.concat(train_set_df).sample(frac=t_frac, random_state=32)\n",
    "        train_set_nbc = pd.concat(train_set_nbc_df).sample(frac=t_frac, random_state=32)\n",
    "        #print train_set\n",
    "        \n",
    "        # Train and Test\n",
    "        w = lr(train_set, test_set)\n",
    "        lr_res[t_frac].append(get_accuracy_lr(w, train_set, test_set))\n",
    "\n",
    "        w = svm(train_set, test_set)\n",
    "        svm_res[t_frac].append(get_accuracy_svm(w, train_set, test_set))\n",
    "        \n",
    "        dict_nbc = nbc(train_set_nbc, test_set_nbc)\n",
    "        nbc_res[t_frac].append(get_accuracy_nbc(dict_nbc, train_set_nbc, test_set_nbc))\n",
    "\n",
    "#print lr_res\n",
    "#print svm_res\n",
    "#print nbc_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = [0.025, 0.05, 0.075, 0.1, 0.15, 0.2]\n",
    "# Get avg accuracy\n",
    "nbc_avg = []\n",
    "lr_avg = []\n",
    "svm_avg = []\n",
    "\n",
    "# Get std error\n",
    "nbc_stdrr = []\n",
    "lr_stdrr = []\n",
    "svm_stdrr = []\n",
    "\n",
    "for i in f:\n",
    "    nbc_avg.append(np.mean(nbc_res[i], axis = 0))\n",
    "    nbc_stdrr.append(np.std(nbc_res[i], axis = 0)/np.sqrt(10))\n",
    "    lr_avg.append(np.mean(lr_res[i], axis = 0))\n",
    "    lr_stdrr.append(np.std(lr_res[i], axis = 0)/np.sqrt(10))\n",
    "    svm_avg.append(np.mean(svm_res[i], axis = 0))\n",
    "    svm_stdrr.append(np.std(svm_res[i], axis = 0)/np.sqrt(10))\n",
    "\n",
    "for i in range(len(f)):\n",
    "    f[i] *= 9 * 520\n",
    "\n",
    "#print lr_avg, svm_avg\n",
    "    \n",
    "fig = plt.figure()\n",
    "plt.plot(f, nbc_avg, color='red', label='NBC')\n",
    "plt.plot(f, lr_avg, color='green', label='LR')\n",
    "plt.plot(f, svm_avg, color='blue', label='SVM')\n",
    "\n",
    "plt.errorbar(f, nbc_avg, nbc_stdrr, color='red')\n",
    "plt.errorbar(f, lr_avg, lr_stdrr, color='green')\n",
    "plt.errorbar(f, svm_avg, svm_stdrr, color='blue')\n",
    "\n",
    "plt.xlabel(\"t_frac\")\n",
    "plt.ylabel(\"accuracy\");\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('./cv.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=15.415948619949303, pvalue=2.6874121443687926e-08)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(lr_avg, svm_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
